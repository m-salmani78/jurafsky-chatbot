{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - CA6\n",
    "* **Name:** Mohammad Mahdi Salmani\n",
    "* **Student id:** 810102174"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import LocalFileStore\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_together import ChatTogether\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Literal\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from IPython.core.display import Markdown\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import CacheBackedEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs.json\") as f:\n",
    "    configs = json.loads(f.read())\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = configs[\"api\"][\"TAVILY_API_KEY\"]\n",
    "os.environ[\"TOGETHER_API_KEY\"] = configs[\"api\"][\"TOGETHER_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl pdf list from site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://stanford.edu/~jurafsky/slp3/2.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/3.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/4.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/5.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/6.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/7.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/8.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/9.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/10.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/11.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/13.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/14.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/15.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/16.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/17.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/18.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/19.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/20.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/21.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/22.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/23.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://stanford.edu/~jurafsky/slp3/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "chapters = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if '.pdf' in link['href'] and link['href'].split('.')[0].isdigit():\n",
    "        chapters.append(link['href'])\n",
    "\n",
    "pdf_links = [url+link for link in chapters]\n",
    "pdf_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pdf_links = pdf_links[:10] # Just retrieve from Chapter I: Fundamental Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:42<00:00, 16.28s/it]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for pdf_link in tqdm(selected_pdf_links):\n",
    "    loader = PyPDFLoader(pdf_link)\n",
    "    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b29bd46ed14d728ccd0703279b5694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   2%|2         | 10.5M/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd9133d11db434884af3959ffd312d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02be9d7f7f2b432498f0175e1a7f5621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9e73d2a0814319a4679cd1887d5984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5842df97c84a4a9ea584b3bf1071372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12109bebd6440a389b55bb19441677b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_function = HuggingFaceEmbeddings(show_progress=True, multi_process=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = LocalFileStore(\"./embedding_cache/\")\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(embedding_function, store, namespace=embedding_function.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "vector_store = FAISS.from_documents(documents=chunks, embedding=cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Score: 0.589, Metadata: {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 0}\n",
      "\n",
      "the prior context, in its recurrent connections , allowing the model’s decision to\n",
      "depend on information from hundreds of words in the past. We’ll see how to apply\n",
      "the model to the task of language mo...\n",
      "\n",
      "[2] Score: 0.562, Metadata: {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 23}\n",
      "\n",
      "covered:\n",
      "• In simple Recurrent Neural Networks sequences are processed one element at\n",
      "a time, with the output of each neural unit at time tbased both on the current\n",
      "input at tand the hidden layer from...\n",
      "\n",
      "[3] Score: 0.553, Metadata: {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 26}\n",
      "\n",
      "neural networks. SemEval-2016 .\n",
      "Gers, F. A., J. Schmidhuber, and F. Cummins. 2000. Learn-\n",
      "ing to forget: Continual prediction with lstm. Neural\n",
      "computation , 12(10):2451–2471.\n",
      "Giles, C. L., G. M. Kuhn...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Recurrent Neural Networks\"\n",
    "results = vector_store.similarity_search_with_relevance_scores(query, k=3)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f'[{i+1}] Score: {result[1]:.3f}, Metadata: {result[0].metadata}')\n",
    "    print(f'\\n{result[0].page_content[:200]}...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    \"What is the advantage of Bidirectional RNNs?\",\n",
    "    \"What is the differences between a stack and a queue.\",\n",
    "    \"Who is the president of United States?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q1] What is the advantage of Bidirectional RNNs?\n",
      "\n",
      "Retrieve 1) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 0}\n",
      "\n",
      "the prior context, in its recurrent connections , allowing the model’s decision to\n",
      "depend on information from hundreds of words in the past. We’ll see how to apply\n",
      "the model to the task of language mo...\n",
      "\n",
      "Retrieve 2) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 23}\n",
      "\n",
      "covered:\n",
      "• In simple Recurrent Neural Networks sequences are processed one element at\n",
      "a time, with the output of each neural unit at time tbased both on the current\n",
      "input at tand the hidden layer from...\n",
      "\n",
      "Retrieve 3) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 26}\n",
      "\n",
      "neural networks. SemEval-2016 .\n",
      "Gers, F. A., J. Schmidhuber, and F. Cummins. 2000. Learn-\n",
      "ing to forget: Continual prediction with lstm. Neural\n",
      "computation , 12(10):2451–2471.\n",
      "Giles, C. L., G. M. Kuhn...\n",
      "\n",
      "[Q2] What is the differences between a stack and a queue.\n",
      "\n",
      "Retrieve 1) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 0}\n",
      "\n",
      "the prior context, in its recurrent connections , allowing the model’s decision to\n",
      "depend on information from hundreds of words in the past. We’ll see how to apply\n",
      "the model to the task of language mo...\n",
      "\n",
      "Retrieve 2) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 23}\n",
      "\n",
      "covered:\n",
      "• In simple Recurrent Neural Networks sequences are processed one element at\n",
      "a time, with the output of each neural unit at time tbased both on the current\n",
      "input at tand the hidden layer from...\n",
      "\n",
      "Retrieve 3) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 26}\n",
      "\n",
      "neural networks. SemEval-2016 .\n",
      "Gers, F. A., J. Schmidhuber, and F. Cummins. 2000. Learn-\n",
      "ing to forget: Continual prediction with lstm. Neural\n",
      "computation , 12(10):2451–2471.\n",
      "Giles, C. L., G. M. Kuhn...\n",
      "\n",
      "[Q3] Who is the president of United States?\n",
      "\n",
      "Retrieve 1) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 0}\n",
      "\n",
      "the prior context, in its recurrent connections , allowing the model’s decision to\n",
      "depend on information from hundreds of words in the past. We’ll see how to apply\n",
      "the model to the task of language mo...\n",
      "\n",
      "Retrieve 2) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 23}\n",
      "\n",
      "covered:\n",
      "• In simple Recurrent Neural Networks sequences are processed one element at\n",
      "a time, with the output of each neural unit at time tbased both on the current\n",
      "input at tand the hidden layer from...\n",
      "\n",
      "Retrieve 3) {'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 26}\n",
      "\n",
      "neural networks. SemEval-2016 .\n",
      "Gers, F. A., J. Schmidhuber, and F. Cummins. 2000. Learn-\n",
      "ing to forget: Continual prediction with lstm. Neural\n",
      "computation , 12(10):2451–2471.\n",
      "Giles, C. L., G. M. Kuhn...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "faiss_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "for i, question in enumerate(sample_queries):\n",
    "    print(f'[Q{i+1}] {question}\\n')\n",
    "    results = faiss_retriever.invoke(query)\n",
    "    for j, result in enumerate(results):\n",
    "        print(f'Retrieve {j+1}) {result.metadata}')\n",
    "        print(f'\\n{result.page_content[:200]}...\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3: EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents=chunks, embedding=cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.4, 0.6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='sequence from tto the end of the sequence.\\nAbidirectional RNN (Schuster and Paliwal, 1997) combines two independentbidirectional\\nRNN\\nRNNs, one where the input is processed from the start to the end, and the other from\\nthe end to the start. We then concatenate the two representations computed by the\\nnetworks into a single vector that captures both the left and right contexts of an input\\nat each point in time. Here we use either the semicolon ”;” or the equivalent symbol\\n⊕to mean vector concatenation:\\nht= [hf\\nt;hb\\nt]\\n=hf\\nt⊕hb\\nt (9.18)\\nFig. 9.11 illustrates such a bidirectional network that concatenates the outputs of\\nthe forward and backward pass. Other simple ways to combine the forward and\\nbackward contexts include element-wise addition or multiplication. The output at\\neach step in time thus captures information to the left and to the right of the current\\ninput. In sequence labeling applications, these concatenated outputs can serve as the\\nbasis for a local labeling decision.', metadata={'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 11}),\n",
       " Document(page_content='12 CHAPTER 9 • RNN S AND LSTM S\\nStacked RNNs generally outperform single-layer networks. One reason for this\\nsuccess seems to be that the network induces representations at differing levels of\\nabstraction across layers. Just as the early stages of the human visual system detect\\nedges that are then used for ﬁnding larger regions and shapes, the initial layers of\\nstacked networks can induce representations that serve as useful abstractions for\\nfurther layers—representations that might prove difﬁcult to induce in a single RNN.\\nThe optimal number of stacked RNNs is speciﬁc to each application and to each\\ntraining set. However, as the number of stacks is increased the training costs rise\\nquickly.\\n9.4.2 Bidirectional RNNs\\nThe RNN uses information from the left (prior) context to make its predictions at\\ntime t. But in many applications we have access to the entire input sequence; in\\nthose cases we would like to use words from the context to the right of t. One way', metadata={'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 11}),\n",
       " Document(page_content='9.4 • S TACKED AND BIDIRECTIONAL RNN ARCHITECTURES 13\\nRNN 2 \\nRNN 1x1y2y1y3ynconcatenatedoutputs\\nx2x3xn\\nFigure 9.11 A bidirectional RNN. Separate models are trained in the forward and backward\\ndirections, with the output of each model at each time point concatenated to represent the\\nbidirectional state at that time point.\\nstate of the RNN as the input to a subsequent feedforward classiﬁer. A difﬁculty\\nwith this approach is that the ﬁnal state naturally reﬂects more information about\\nthe end of the sentence than its beginning. Bidirectional RNNs provide a simple\\nsolution to this problem; as shown in Fig. 9.12, we simply combine the ﬁnal hidden\\nstates from the forward and backward passes (for example by concatenation) and\\nuse that as input for follow-on processing.\\nRNN 2 \\nRNN 1x1x2x3xnhn→h1←hn→SoftmaxFFNh1←\\nFigure 9.12 A bidirectional RNN for sequence classiﬁcation. The ﬁnal hidden units from\\nthe forward and backward passes are combined to represent the entire sequence. This com-', metadata={'source': 'https://stanford.edu/~jurafsky/slp3/9.pdf', 'page': 12}),\n",
       " Document(page_content='computed independently of the others using only information seen earlier in the context. (b) Information ﬂow in\\na bidirectional self-attention model. In processing each element of the sequence, the model attends to all inputs,\\nboth before and after the current one.\\nBidirectional encoders overcome this limitation by allowing the self-attention\\nmechanism to range over the entire input, as shown in Fig. 11.1b.\\nWhy bidirectional encoders? The causal models of Chapter 10 are generative\\nmodels, designed to easily generate the next token in a sequence. But the focus\\nof bidirectional encoders is instead on computing contextualized representations of\\nthe input tokens. Bidirectional encoders use self-attention to map sequences of\\ninput embeddings (x1,...,xn)to sequences of output embeddings the same length\\n(y1,...,yn), where the output vectors have been contextualized using information\\nfrom the entire input sequence. These output embeddings are contextualized repre-', metadata={'source': 'https://stanford.edu/~jurafsky/slp3/11.pdf', 'page': 1}),\n",
       " Document(page_content='might use email text or newsgroups). Now compare the statistics of the two\\ncorpora. What are the differences in the most common unigrams between the\\ntwo? How about interesting differences in bigrams?\\n3.10 Add an option to your program to generate random sentences.\\n3.11 Add an option to your program to compute the perplexity of a test set.\\n3.12 You are given a training set of 100 numbers that consists of 91 zeros and 1\\neach of the other digits 1-9. Now we see the following test set: 0 0 0 0 0 3 0 0\\n0 0. What is the unigram perplexity?', metadata={'source': 'https://stanford.edu/~jurafsky/slp3/3.pdf', 'page': 27}),\n",
       " Document(page_content='14 CHAPTER 2 • R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\\nSpeaker demographics : What was, e.g., the age or gender of the text’s authors?\\nCollection process : How big is the data? If it is a subsample how was it sampled?\\nWas the data collected with consent? How was the data pre-processed, and\\nwhat metadata is available?\\nAnnotation process : What are the annotations, what are the demographics of the\\nannotators, how were they trained, how was the data annotated?\\nDistribution : Are there copyright or other intellectual property restrictions?\\n2.4 Simple Unix Tools for Word Tokenization\\nBefore almost any natural language processing of a text, the text has to be normal-\\nized, a task called text normalization . At least three tasks are commonly applied astext\\nnormalization\\npart of any normalization process:\\n1. Tokenizing (segmenting) words\\n2. Normalizing word formats\\n3. Segmenting sentences\\nIn the next sections we walk through each of these tasks, but we’ll ﬁrst start with', metadata={'source': 'https://stanford.edu/~jurafsky/slp3/2.pdf', 'page': 13}),\n",
       " Document(page_content='from all the units in the previous layer, and there is a link between every pair of units\\nfrom two adjacent layers. Thus each hidden unit sums over all the input units.\\nRecall that a single hidden unit has as parameters a weight vector and a bias. We\\nrepresent the parameters for the entire hidden layer by combining the weight vector\\nand bias for each unit iinto a single weight matrix Wand a single bias vector bfor\\nthe whole layer (see Fig. 7.8). Each element Wjiof the weight matrix Wrepresents\\nthe weight of the connection from the ith input unit xito the jth hidden unit hj.\\nThe advantage of using a single matrix Wfor the weights of the entire layer is\\nthat now the hidden layer computation for a feedforward network can be done very\\nefﬁciently with simple matrix operations. In fact, the computation only has three', metadata={'source': 'https://stanford.edu/~jurafsky/slp3/7.pdf', 'page': 6})]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retriever.invoke(sample_queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
