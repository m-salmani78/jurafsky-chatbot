{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - CA6\n",
    "* **Name:** Mohammad Mahdi Salmani\n",
    "* **Student id:** 810102174"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain\\\n",
    "    langchain-community\\\n",
    "    langchain-together\\\n",
    "    langchain-core\\\n",
    "    faiss-cpu\\\n",
    "    faiss-gpu\\\n",
    "    langgraph\\\n",
    "    sentence-transformers\\\n",
    "    gradio\\\n",
    "    pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Literal\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from IPython.core.display import Markdown\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import CacheBackedEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"92a237b154b842a8af1371f10bc4710f92c1be002b4ad6e5c5c29e6914304e42\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl pdf list from site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://stanford.edu/~jurafsky/slp3/2.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/3.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/4.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/5.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/6.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/7.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/8.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/9.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/10.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/11.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/13.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/14.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/15.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/16.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/17.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/18.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/19.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/20.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/21.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/22.pdf',\n",
       " 'https://stanford.edu/~jurafsky/slp3/23.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://stanford.edu/~jurafsky/slp3/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "chapters = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if '.pdf' in link['href'] and link['href'].split('.')[0].isdigit():\n",
    "        chapters.append(link['href'])\n",
    "\n",
    "pdf_links = [url+link for link in chapters]\n",
    "pdf_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for pdf_link in pdf_links[:2]:\n",
    "    loader = PyPDFLoader(pdf_link)\n",
    "    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"\"\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': False}\n",
    "# embedding_function = HuggingFaceEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs=model_kwargs,\n",
    "#     encode_kwargs=encode_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CacheBackedEmbeddings.__init__() got an unexpected keyword argument 'cache_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# embedding_function = HuggingFaceEmbeddings(show_progress=True, multi_process=True)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cache_backed_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mCacheBackedEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: CacheBackedEmbeddings.__init__() got an unexpected keyword argument 'cache_dir'"
     ]
    }
   ],
   "source": [
    "# embedding_function = HuggingFaceEmbeddings(show_progress=True, multi_process=True)\n",
    "cache_backed_embeddings = CacheBackedEmbeddings(embedding_function, cache_dir=\"embedding_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = \"embedding_cache.json\"\n",
    "\n",
    "def load_cache():\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    with open(cache_file, \"w\") as f:\n",
    "        json.dump(cache, f)\n",
    "\n",
    "cache = load_cache()\n",
    "cached_embedder = CacheBackedEmbeddings(base_embedder=embedder, cache=cache)\n",
    "\n",
    "vectorstore = FAISS.from_texts(split_documents, cached_embedder)\n",
    "\n",
    "vectorstore.save(\"faiss_index\")\n",
    "\n",
    "# ذخیره کردن Cache\n",
    "save_cache(cached_embedder.cache)\n",
    "\n",
    "# بارگذاری مجدد FAISS index (اختیاری)\n",
    "# vectorstore = FAISS.load(\"faiss_index\", cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
